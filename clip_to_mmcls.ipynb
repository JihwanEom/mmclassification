{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abc6cda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3766f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = torch.load('ViT-L-14-336px.pt').state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6cd977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_openclip(ckpt):\n",
    "    new_ckpt = OrderedDict()\n",
    "\n",
    "    for k, v in list(ckpt.items()):\n",
    "        if 'visual' not in k:\n",
    "            continue\n",
    "        k = k.replace('visual.', '')\n",
    "        k = k.replace('transformer.', '')\n",
    "        new_v = v\n",
    "        if k.startswith('proj'):\n",
    "            new_k = 'neck.proj'\n",
    "            new_ckpt[new_k] = new_v\n",
    "            continue\n",
    "        elif k.startswith('conv1'):\n",
    "            new_k = k.replace('conv1', 'patch_embed.projection')\n",
    "        elif k.startswith('ln_pre'):\n",
    "            new_k = k.replace('ln_pre.', 'pre_norm.')\n",
    "        elif k.startswith('resblocks'):\n",
    "            new_k = k.replace('resblocks.', 'layers.')\n",
    "            if 'ln_1' in k:\n",
    "                new_k = new_k.replace('ln_1', 'ln1')\n",
    "            elif 'ln_2' in k:\n",
    "                new_k = new_k.replace('ln_2', 'ln2')\n",
    "            elif 'in_proj_weight' in k:\n",
    "                new_k = new_k.replace('in_proj_weight', 'qkv.weight')\n",
    "            elif 'in_proj_bias' in k:\n",
    "                new_k = new_k.replace('in_proj_bias', 'qkv.bias')\n",
    "            if 'out_proj' in k:\n",
    "                new_k = new_k.replace('out_proj', 'proj')\n",
    "            elif 'mlp.c_fc' in k:\n",
    "                new_k = new_k.replace('mlp.c_fc', 'ffn.layers.0.0')\n",
    "            elif 'mlp.c_proj' in k:\n",
    "                new_k = new_k.replace('mlp.c_proj', 'ffn.layers.1')\n",
    "        elif k.startswith('class_embedding'):\n",
    "            new_v = v[None, None, :]\n",
    "            new_k = k.replace('class_embedding', 'cls_token')\n",
    "        elif k.startswith('positional_embedding'):\n",
    "            new_v = v[None, ...]\n",
    "            new_k = k.replace('positional_embedding', 'pos_embed')\n",
    "        elif k.startswith('ln_post'):\n",
    "            new_k = k.replace('ln_post', 'ln1')\n",
    "        else:\n",
    "            new_k = k\n",
    "\n",
    "        if not new_k.startswith('head'):\n",
    "            new_k = 'backbone.' + new_k\n",
    "        new_ckpt[new_k] = new_v\n",
    "    return new_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29557421",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = convert_openclip(clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6c780c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x, 'clip2mmcls_converted.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e94f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie",
   "language": "python",
   "name": "aie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
